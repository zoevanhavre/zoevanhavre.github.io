---
title: 'Wombat - 2016 '
author: "Dr Zoe van Havre"
date: '`r Sys.Date()`'
output:
  ioslides_presentation:
    incremental: yes
    css: custom.css
    keep_md: yes
    logo: Images/logo.png
    transition: faster
    widescreen: yes
  beamer_presentation:
    colortheme: dove
    fonttheme: professionalfonts
    highlight: haddock
    incremental: yes
    slide_level: 2
    theme: Szeged
  slidy_presentation:
    incremental: yes
subtitle: 'Simple tools for complex problems: making molehills out of mountains'
fontsize: 10pt
---



```{r, echo = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  cache = FALSE
)
```

```{r, echo=FALSE, include=FALSE, cache=TRUE}
# OPTIONS
require(knitr)
# Set opts_knit
opts_knit$set(cache = TRUE,
	            error = TRUE,
              fig.height = 6, 
              fig.width = 8,
              pointsize=6)

# Set opts_chunk
opts_chunk$set(fig.width=7, fig.height=5, pointsize=8)
load("~/Google Drive/Work/CSIRO_P1/WOMBAT Talk 2016/Results_All_ForPres.RDATA")
```



```{r,echo=FALSE,cache=TRUE}
require(ggplot2, quietly=TRUE)
require(tidyr, quietly=TRUE)

# function:
DensityPlot_HC<-function(ME, BigY_HC_inFunk=BigY_HC, 
                            .All.tp_inFunk=.All.tp){ 
	  y.now=BigY_HC_inFunk[,ME]
    region.now=names(BigY_HC_inFunk)[ME]
    
    # pars:
    pars.now    <-aggregate( Estimate~ variable+k,
      data=.All.tp_inFunk[ .All.tp_inFunk$Region %in% region.now,],
      mean)

    Mix.pars<-list(  "Mu" =c(pars.now[pars.now$variable%in%"Mu",3]),
                     "Var"=c(pars.now[pars.now$variable%in%"Sig",3]),
                     "P"  =c(pars.now[pars.now$variable%in%"P",3]))
  	In <-list("Y"=y.now, "mu"=Mix.pars[[1]], "sigma"=Mix.pars[[2]], "lambda"=Mix.pars[[3]])
    x     <- seq(0.5,4,len=1000)
  	pars    <- data.frame(comp=paste("K",c(1:length(In$lambda)), sep="_"), In$mu, In$sig, In$lambda )
  	em.df   <- data.frame(x=rep(x,each=nrow(pars)),pars)
  	em.df$y <- with(em.df,In.lambda*dnorm(x,mean=In.mu,sd=sqrt(In.sig)))
  	em.df$In.mu<-	factor(em.df$In.mu)
  	
    if(sum(pars.now$k==2)==3) {levels(em.df$In.mu)<-c("HC_k_1", "HC_k_2")
    }else{  levels(em.df$In.mu)<-c("HC_k_1")}

		#model found
		md<-ggplot(data.frame(x=In$Y),aes(x,y=..density..)) + xlab("SUVR")+ylab("Density")+
        geom_histogram(fill="deepskyblue4", alpha = 0.8, binwidth=diff(range(y.now))/50)+
		    geom_polygon(data=em.df,aes(x,y,fill=comp),color="black", alpha=0.5, size=0.2)+
		    scale_fill_manual("Cluster",labels=format(em.df$In.mu,digits=3), values=c( "dodgerblue4", "cyan2"))+ 
		    theme_bw()+
#		  geom_vline(data=pars, aes(xintercept=In.mu),color="black",linetype="dashed", size=0.3)+
#		    theme(legend.position="none")+
#		    annotate("text", x = pars$In.mu[1]-0.01, y =-0.25, label = round(pars$In.mu[1], 2), angle=90, size=2)+ 
		ggtitle(bquote(atop(.(region.now), atop(italic("HC (Blue)")))))+
			 coord_cartesian(ylim= c(-0.5,  max(em.df$y)+0.5))
		
	 return(md)}



# function:
DensityPlot_Both<-function(ME, BigY_HC_inFunk=BigY_HC, 
                            BigY_AD_inFunk=BigY_AD, 
                            .All.tp_inFunk=.All.tp ,
                            .All_AD_inFunk=.All_AD){ 
	  y.now=BigY_HC_inFunk[,ME]
    region.now=names(BigY_HC_inFunk)[ME]
    y.ad.now=BigY_AD_inFunk[,ME]
    
    # pars:
    pars.now    <-aggregate( Estimate~ variable+k,
      data=.All.tp_inFunk[ .All.tp_inFunk$Region %in% region.now,],
      mean)
    .All_AD.tp  <-.All_AD_inFunk[.All_AD_inFunk$TopModel %in% TRUE,]
    pars.now.ad <-aggregate(Estimate~ variable+k,
                           data=.All_AD.tp[ .All_AD.tp$Region %in% region.now,],
                           mean)

    Mix.pars<-list(  "Mu" =c(pars.now.ad[2,3], pars.now[pars.now$variable%in%"Mu",3]),
                     "Var"=c(pars.now.ad[3,3], pars.now[pars.now$variable%in%"Sig",3]),
                     "P"  =c(pars.now.ad[1,3], pars.now[pars.now$variable%in%"P",3]))
  	In <-list("Y"=y.now, "mu"=Mix.pars[[1]], "sigma"=Mix.pars[[2]], "lambda"=Mix.pars[[3]])
    x     <- seq(0.5,4,len=1000)
  	pars    <- data.frame(comp=paste("K",c(1:length(In$lambda)), sep="_"), In$mu, In$sig, In$lambda )
  	em.df   <- data.frame(x=rep(x,each=nrow(pars)),pars)
  	em.df$y <- with(em.df,In.lambda*dnorm(x,mean=In.mu,sd=sqrt(In.sig)))
  	em.df$In.mu<-	factor(em.df$In.mu)
  	
    if(sum(pars.now$k==2)==3) {levels(em.df$In.mu)<-c("HC_k_1", "HC_k_2", "AD_k_1")
    }else{  levels(em.df$In.mu)<-c("HC_k_1", "AD_k_1")}

		#model found
		md<-ggplot(data.frame(x=In$Y),aes(x,y=..density..)) + xlab("SUVR")+ylab("Density")+
		   	geom_histogram( data=data.frame(xad=y.ad.now), aes(xad,y=..density..), fill="firebrick1", alpha = 0.3,binwidth=diff(range(y.ad.now))/50)+
        geom_histogram(fill="deepskyblue4", alpha = 0.8, binwidth=diff(range(y.now))/50)+
		    geom_polygon(data=em.df,aes(x,y,fill=comp),color="black", alpha=0.5, size=0.2)+
		    scale_fill_manual("Cluster",labels=format(em.df$In.mu,digits=3), values=c("firebrick1", "dodgerblue4", "cyan2"))+ 
		    theme_bw()+
#		  geom_vline(data=pars, aes(xintercept=In.mu),color="black",linetype="dashed", size=0.3)+
#		    theme(legend.position="none")+
#		    annotate("text", x = pars$In.mu[1]-0.01, y =-0.25, label = round(pars$In.mu[1], 2), angle=90, size=2)+ 
		ggtitle(bquote(atop(.(region.now), atop(italic("HC (Blue) & AD (Red)")))))+
			 coord_cartesian(ylim= c(-0.5,  max(em.df$y)+0.5))
		
	 return(md)}


```


## Who am I?

- PhD in statistics, from QUT \& Paris-Dauphine
- I live in Brisbane, by way of Canada, New Zealand, and various places in between.
- *Key areas*:
    - <img style="width: 18px; height: 18px; margin: 0; vertical-align: center;" src="http://i.stack.imgur.com/DSxUV.png" alt="" scale="0"> Bayesian statistics
    - Mixture and hidden Markov models, 
    - Bio-statistics/informatics/security,
- *Research interests*
    - data driven, accessible, intuitive tools
    - **making data analysis easier**


## What drives me?

The most common question asked since I started to pursue Statistics has been:

<div class="centered" >
**"Why...?"**
</div>

I can share my three reasons!

1. A sense of urgency,
2. Tantalizing hope,
3. Boundless excitement.



# Urgency?

## Can we keep up?

The exponential growth of computing is not slowing down!

* New types of data and new challenges require new approaches
* This means that in 10 years, expect to see 1000-fold growth

It is notoriously hard for us to understand what this means.

* If we symbolise all of our computational advances by this dot $\rightarrow \cdot$

    in 10 years:
 * <img src="Images/1000-dots.png" width=900 alt="1000 dots">


# Hope...

## Hope
- Opinions are changing fast, and everyone is coming onboard!
- There are low hanging fruits to make better, easier tools.
    - __the traditional way__: adapt asymptotic theory to small sample sizes.
    - __the future__: to take advantage of Big Data (i.e. closer to truth)
    - <div align="center">
    <img height="350" src="Images/Mammoth.png" frameborder="0" ></img>
    </div>
   



# Excitement!

## Better tools make data analysis easier
Amazing things happen when data analysis combines clear research questions,  appropriate data, and suitable, accessible tools.

* Accessibility: usability, and understanding what the tool does.  
     _Hammers and nails do not come with instruction manuals._
* People can sometimes do more with less.
* Simple models are less likely to be wrongly used. 

> It doesnt have to be just "analysis", it can be exploration, discovery, and a little bit magical. 



# A short story about Alzheimer's Disease| featuring... overfitted mixture models!



## Key background

Alzheimer's Disease (AD) currently affects over 342,800 Australians, and this number is expected to rise to 900,000 by 2050.

Cognitive changes indicate something is amiss, but these occur late in the disease ($\geq$ 20 years).

During this time, AD causes irreversible damage to the brain:

> - accumulation of **amyloid $\beta$**,
> - neurofibrillary tangles, 
> - overall atrophy.

To better research and treat AD, we need to be able to treat it earlier.


## How can we help improve early detection

To better tackle AD, we need to be able to treat it earlier.

__Goal: identify individuals likely to be in the early stage of AD.__

* Large repository of data exists thanks to AIBL study  (REF)
* SUVR available for 393 individuals, for a set of _brain regions_ (pre-processed)
    * 290 HC, 103 AD 
* Traditionally first thing to do is compare AD to HC, of course
* But some of the clinically "Healthy" HC individuals these must be in _early stage AD_

-------


<div align="center">
<img height="600" src="Images/FarSidePenguin.jpg" frameborder="0" allowfullscreen></img>


-----------

* If different types of individuals are present and not modelled, any conclusion drawn from comparing AD to HC may be skewed or entirely invalid. 
* Our research problem is causing a problem...  
* Assume distribution of SUVR in each region _may_ depend on unknown number of groups
* Assume these are normally distributed
* Assume nothing about how AD develops spatially and longitudinally
    * Model each region separetely.
* We want to know if there are subgroups in the HC irrespective of AD results
    * Model HC and AD seperately.
* this leads to several, relatively simple models, but with a lot of unknowns
    * number of groups, all group parameters
* Overfitted mixture models can be useful here.

## The Data

The study consists of `r dim(BigY)[1]` individuals, composed of Healthy Controls (HC), MCI, and AD patients.

```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
	table(BigY$Type)
```

------

```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
require(ggplot2, quietly=TRUE)
require(reshape2, quietly=TRUE)
g.hist.SURV<- ggplot(melt(BigY[,c(4:28)]), aes(value, group=variable)) 
g.hist.SURV<- g.hist.SURV+ geom_histogram(position="dodge")+ xlab("SURV")+ ylab("Frequency")+ facet_wrap(~variable,ncol=5)+theme_bw()
g.hist.SURV
```

# Overfitting with Zmix

## Overfitted mixture models
We can model an unknown number of groups using **overfitted mixture models**, a Bayesian method found in the R package "Zmix".

  * too many groups are included in a mixture model
  * extra groups __empty out__
  * probability of number of occupied groups  
  * data driven and fully parametric
  * Bayesian, but straightforward 
  * Assumes only that up to $K$ groups are normally distributed with an unknown mean and variance. 

## How it's done

Install the package
```{r, eval=FALSE}
install_github('zoevanhavre/Zmix') # Thank you Hadley!
library(Zmix)
```

Run the model with $K=5$ groups

```{r, eval=FALSE}
### <b> 
Zmix.Y<-Zmix_univ_tempered (Y, iter=50000, k=5)  
### </b>
```

Process the results
```{r, eval=FALSE}
Proc.Zmix.Y<-Process_Output_Zmix(Zmix.Y, Burn=25000)
```


[Check out the README for more examples](https://github.com/zoevanhavre/Zmix)


# Results


--------------

```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
require(ggplot2, quietly=TRUE)
	gp.PropHigh.1<-ggplot(SUVR_ProportionHigh.1, aes(x=Region, y=PropHigh))+ geom_bar(stat="identity", fill="cyan2") + ggtitle("Prevalence of second cluster")+ xlab("Regions")+theme_bw()+ylab("Proportion of (HC) Patients")+theme(axis.text.x = element_text(angle = 90, hjust = 1))
	# PLOT!!!
	gp.PropHigh.1
```


--------------

```{r, echo=FALSE, warning=FALSE, fig.width = 4 , fig.height = 3, cache=TRUE}
require(ggplot2, quietly=TRUE)
DensityPlot_HC(5) 
DensityPlot_HC(10)
DensityPlot_HC(15)
DensityPlot_HC(29)

```

-----------

```{r, echo=FALSE, warning=FALSE,fig.width = 4 , fig.height = 3,cache=TRUE}
require(ggplot2, quietly=TRUE)

DensityPlot_Both(5)
DensityPlot_Both(10)
DensityPlot_Both(15)
DensityPlot_Both(29)

```



----------
```{r, echo=FALSE, warning=FALSE, fig.width = 4 , fig.height = 3,cache=TRUE}
require(ggplot2, quietly=TRUE)

	ggplot(cr.tm.K02, aes( Region , Mu))+
		geom_boxplot(aes(col=factor(k)), outlier.size=0.1)+ggtitle("HC, ordered by lower means")+
		theme(axis.text.x = element_text(angle = 90, hjust = 1))+geom_hline(yintercept=1.5 )



```




## Structure of results
```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
heatmap.3(t(ForSIMI_num),col=c( "dodgerblue4", "cyan2"),Rowv = F, ColSideColors= column_annotation2, hclust=hclustfunc, distfun=distfunc,   key=FALSE, margins = c(3,10),cexRow = .6,cexCol = 0.001, xlab="Patients (HC only)")
```



### Genotype by Groups

```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
require(tidyr, quietly=TRUE)
require(ggplot2, quietly=TRUE)

df.new<-aggregate(ApoE~ Region+k_hilo, droplevels(top_demogs),function(x) prop.table(table(x)) )
df.new<-as.data.frame(as.matrix(df.new))
df.new.t<-gather(df.new,key=Genotype, value=Proportion,ApoE.ApoE_Neg,  ApoE.ApoE_Pos  )
df.new.t$Proportion<- factor2numeric( df.new.t$Proportion)
levels(df.new.t$k_hilo)<-c("HC: high mean group","HC: low mean group")
ggplot(df.new.t,aes(Region,Proportion))+geom_bar(aes(fill=Genotype),stat="identity",position='dodge')+facet_grid(~k_hilo)+theme_bw() +  theme(axis.text.x = element_text(angle = 90, hjust = 1), axis.text.y = element_text( hjust = 1))+ggtitle("Genotype by Zmix cluster")+ scale_fill_manual("Genotype",labels=c("ApoE- (good)", "ApoE+ (bad)"), values=c("red", "yellow"))  


```

## Memory Status by Groups

```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
require(tidyr, quietly=TRUE)

# memory status
df.new<-aggregate(Austin~ Region+k_hilo, droplevels(top_demogs),function(x) prop.table(table(x)) )
df.new<-as.data.frame(as.matrix(df.new))
df.new.t<-gather(df.new,key=Diagnosis, value=Proportion,3,   4  )
df.new.t$Proportion<- factor2numeric( df.new.t$Proportion)
levels(df.new.t$Diagnosis)<-c("Memory Complainer (HC)"   ,  "Non-Memory Complainer (HC)")
levels(df.new.t$k_hilo)<-c("HC: high mean group","HC: low mean group")
ggplot(df.new.t,aes(Region,Proportion))+geom_bar(aes(fill=Diagnosis),stat="identity",position='dodge')+facet_grid(~k_hilo)+theme_bw() +  theme(axis.text.x = element_text(angle = 90, hjust = 1), axis.text.y = element_text( hjust = 1))+ggtitle("Memory Status by Zmix cluster")+ scale_fill_manual("Memory",labels=c("Complainer", "Non-Complainer"), values=c("orange", "green"))  

```

## Summary

* __one__ or __two__ Normal groups likely to be present. 
* Prevalence of 2nd group similar across regions, 
* Allocation to 2nd group highly correlated across individuals,
* Distribution of HC clusters suggests
    - SURV dist uniformly if you remove high mean group
    - high mean groups closely resembles the distribution of SUVR in AD, but shifted to a lower mean





------
<div align="center">
<iframe width="560" height="315" src="http://www.youtube.com/embed/9bZkp7q19f0?rel=0" frameborder="0" allowfullscreen></iframe>
   </iframe>
</div>




------




<slide class="segue dark background">
<hgroup class="auto-fadein">
<h2>Light Fade</h2>
</hgroup>
<article id="sets-article-class" class="h1_class">
</article>
</slide>
