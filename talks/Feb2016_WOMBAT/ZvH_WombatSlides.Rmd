---
title: 'Wombat - 2016 '
author: "Dr Zoe van Havre"
output:
  ioslides_presentation:
    css: custom.css
    incremental: yes
    keep_md: yes
    logo: Images/logo.png
    transition: faster
  beamer_presentation:
    incremental: yes
    slide_level: 2
    toc: yes
  slidy_presentation:
    incremental: yes
subtitle: 'Simple tools for complex problems: making molehills out of mountains'
fontsize: 10pt
---


```{r, echo=FALSE, include=FALSE, cache=TRUE}
# OPTIONS
require(knitr)
# Set opts_knit
opts_knit$set(echo=FALSE, 
              warning=FALSE, 
              message=FALSE,
              cache = TRUE,
	            error = TRUE,
              fig.height = 6, 
              fig.width = 8,
              pointsize=6)

# Set opts_chunk
opts_chunk$set(fig.width=7, fig.height=5, pointsize=8)
load("~/Google Drive/Work/CSIRO_P1/WOMBAT Talk 2016/Results_All_ForPres.RDATA")
```



```{r,echo=FALSE,cache=TRUE}
require(ggplot2, quietly=TRUE)
require(tidyr, quietly=TRUE)

# function:
DensityPlot_HC<-function(ME, BigY_HC_inFunk=BigY_HC, 
                            .All.tp_inFunk=.All.tp){ 
	  y.now=BigY_HC_inFunk[,ME]
    region.now=names(BigY_HC_inFunk)[ME]
    
    # pars:
    pars.now    <-aggregate( Estimate~ variable+k,
      data=.All.tp_inFunk[ .All.tp_inFunk$Region %in% region.now,],
      mean)

    Mix.pars<-list(  "Mu" =c(pars.now[pars.now$variable%in%"Mu",3]),
                     "Var"=c(pars.now[pars.now$variable%in%"Sig",3]),
                     "P"  =c(pars.now[pars.now$variable%in%"P",3]))
  	In <-list("Y"=y.now, "mu"=Mix.pars[[1]], "sigma"=Mix.pars[[2]], "lambda"=Mix.pars[[3]])
    x     <- seq(0.5,4,len=1000)
  	pars    <- data.frame(comp=paste("K",c(1:length(In$lambda)), sep="_"), In$mu, In$sig, In$lambda )
  	em.df   <- data.frame(x=rep(x,each=nrow(pars)),pars)
  	em.df$y <- with(em.df,In.lambda*dnorm(x,mean=In.mu,sd=sqrt(In.sig)))
  	em.df$In.mu<-	factor(em.df$In.mu)
  	
    if(sum(pars.now$k==2)==3) {levels(em.df$In.mu)<-c("HC_k_1", "HC_k_2")
    }else{  levels(em.df$In.mu)<-c("HC_k_1")}

		#model found
		md<-ggplot(data.frame(x=In$Y),aes(x,y=..density..)) + xlab("SUVR")+ylab("Density")+
        geom_histogram(fill="deepskyblue4", alpha = 0.8, binwidth=diff(range(y.now))/50)+
		    geom_polygon(data=em.df,aes(x,y,fill=comp),color="black", alpha=0.5, size=0.2)+
		    scale_fill_manual("Cluster",labels=format(em.df$In.mu,digits=3), values=c( "dodgerblue4", "cyan2"))+ 
		    theme_bw()+
#		  geom_vline(data=pars, aes(xintercept=In.mu),color="black",linetype="dashed", size=0.3)+
#		    theme(legend.position="none")+
#		    annotate("text", x = pars$In.mu[1]-0.01, y =-0.25, label = round(pars$In.mu[1], 2), angle=90, size=2)+ 
		ggtitle(bquote(atop(.(region.now), atop(italic("HC (Blue)")))))+
			 coord_cartesian(ylim= c(-0.5,  max(em.df$y)+0.5))
		
	 return(md)}



# function:
DensityPlot_Both<-function(ME, BigY_HC_inFunk=BigY_HC, 
                            BigY_AD_inFunk=BigY_AD, 
                            .All.tp_inFunk=.All.tp ,
                            .All_AD_inFunk=.All_AD){ 
	  y.now=BigY_HC_inFunk[,ME]
    region.now=names(BigY_HC_inFunk)[ME]
    y.ad.now=BigY_AD_inFunk[,ME]
    
    # pars:
    pars.now    <-aggregate( Estimate~ variable+k,
      data=.All.tp_inFunk[ .All.tp_inFunk$Region %in% region.now,],
      mean)
    .All_AD.tp  <-.All_AD_inFunk[.All_AD_inFunk$TopModel %in% TRUE,]
    pars.now.ad <-aggregate(Estimate~ variable+k,
                           data=.All_AD.tp[ .All_AD.tp$Region %in% region.now,],
                           mean)

    Mix.pars<-list(  "Mu" =c(pars.now.ad[2,3], pars.now[pars.now$variable%in%"Mu",3]),
                     "Var"=c(pars.now.ad[3,3], pars.now[pars.now$variable%in%"Sig",3]),
                     "P"  =c(pars.now.ad[1,3], pars.now[pars.now$variable%in%"P",3]))
  	In <-list("Y"=y.now, "mu"=Mix.pars[[1]], "sigma"=Mix.pars[[2]], "lambda"=Mix.pars[[3]])
    x     <- seq(0.5,4,len=1000)
  	pars    <- data.frame(comp=paste("K",c(1:length(In$lambda)), sep="_"), In$mu, In$sig, In$lambda )
  	em.df   <- data.frame(x=rep(x,each=nrow(pars)),pars)
  	em.df$y <- with(em.df,In.lambda*dnorm(x,mean=In.mu,sd=sqrt(In.sig)))
  	em.df$In.mu<-	factor(em.df$In.mu)
  	
    if(sum(pars.now$k==2)==3) {levels(em.df$In.mu)<-c("HC_k_1", "HC_k_2", "AD_k_1")
    }else{  levels(em.df$In.mu)<-c("HC_k_1", "AD_k_1")}

		#model found
		md<-ggplot(data.frame(x=In$Y),aes(x,y=..density..)) + xlab("SUVR")+ylab("Density")+
		   	geom_histogram( data=data.frame(xad=y.ad.now), aes(xad,y=..density..), fill="firebrick1", alpha = 0.3,binwidth=diff(range(y.ad.now))/50)+
        geom_histogram(fill="deepskyblue4", alpha = 0.8, binwidth=diff(range(y.now))/50)+
		    geom_polygon(data=em.df,aes(x,y,fill=comp),color="black", alpha=0.5, size=0.2)+
		    scale_fill_manual("Cluster",labels=format(em.df$In.mu,digits=3), values=c("firebrick1", "dodgerblue4", "cyan2"))+ 
		    theme_bw()+
#		  geom_vline(data=pars, aes(xintercept=In.mu),color="black",linetype="dashed", size=0.3)+
#		    theme(legend.position="none")+
#		    annotate("text", x = pars$In.mu[1]-0.01, y =-0.25, label = round(pars$In.mu[1], 2), angle=90, size=2)+ 
		ggtitle(bquote(atop(.(region.now), atop(italic("HC (Blue) & AD (Red)")))))+
			 coord_cartesian(ylim= c(-0.5,  max(em.df$y)+0.5))
		
	 return(md)}


```


## Who am I?

- PhD in statistics, from QUT \& Paris-Dauphine
- I live in Brisbane, by way of Canada, New Zealand, and various places in between.
- *Key areas*:
    - <img style="width: 18px; height: 18px; margin: 0; vertical-align: center;" src="http://i.stack.imgur.com/DSxUV.png" alt="" scale="0"> Bayesian statistics
    - Mixture and hidden Markov models, 
    - Bio-statistics/informatics/security,
- *Research interests*
    - data driven, accessible, intuitive tools
    - **making data analysis easier**


## What drives me?

The most common question asked since I started to pursue Statistics has been

<div class="centered">
**"Why...?"**
</div>

- I have three reasons:

1. A sense of urgency,
2. tantalizing hope,
3. boundless excitement.



# Urgency?

## Can we keep up?

- The exponetial growth of computing has not slowed down.
- New types of data and new challenges require new approaches
- 

----------------




# Hope...


## Not all change is bad
- Everyone is coming onboard! amazing advances
- Data-science is a thing now
- We are standing on a methodological goldmine...
    - **the traditional way**: 
        - Develop methods based on large sample theory.  
        - Adapt / make assumptions. to deploy on realistic sample sizes
    - **the future?** 
        - Rework common tools to be closer to underlying theory
        - This usually means Bayesian, yes. Sorry. 
        - Asymptotic theory $\rightarrow$ Methods $\rightarrow$ Big Data  $\rightarrow$ Theoretically Supported Results
    
    
## 3. Excitement!

Amazing things happen when data analysis combines

- clear research questions, 
- suitable tools, and 
- appropriate data



# A short story about Alzheimer's Disease| featuring... overfitted mixture models!



## Key background

Alzheimer's Disease (AD) currently affects over 342,800 Australians, and this number is expected to rise to 900,000 by 2050.

Cognitive changes indicated something is amiss, but these occur late in the disease ($\geq$ 20 years).

During this time, AD causes irreversible damage to the brain:

- accumulation of **amyloid $\beta$**,
- neurofibrillary tangles, 
- overall atrophy.

To better researchand treat AD, we need to be able to treat it earlier.


## What you need to know

- Alzheimer's Disease (AD) is something we need to address
- disease development is very slow
- cognitive changes indetectable for $\geq$ 20 years
- Tests which assess physical change are $ $ $ and intrusive


## How can we help improve early detection

To better tackle AD, we need to be able to treat it earlier.

- we know little about how AD behaves in its early stage
- could compare known cases to controls, 
    - does not target early stage of AD
- **would like to identify individuals likely to be in early stage of AD**
 
## How? 

- large repository of data exists thanks to AIBL study 
- many data types, potential variables, time points, and sources
- possibilites = *endless* (thousands of potential approaches)
- What now...?

## The Data

The study consists of `r dim(BigY)[1]` individuals, composed of Healthy Controls (HC), MCI, and AD patients.

```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
	table(BigY$Type)
```

------

```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
require(ggplot2, quietly=TRUE)
require(reshape2, quietly=TRUE)
g.hist.SURV<- ggplot(melt(BigY[,c(4:28)]), aes(value, group=variable)) 
g.hist.SURV<- g.hist.SURV+ geom_histogram(position="dodge")+ xlab("SURV")+ ylab("Frequency")+ facet_wrap(~variable,ncol=5)+theme_bw()
g.hist.SURV
```

# Overfitting with Zmix

## Overfitted mixture models
We can model an unknown number of groups using **overfitted mixture models**, a Bayesian method found in the R package "Zmix".

  - too many groups are included in the model,
  - extra groups **empty out**
  - data driven and fully parametric, 
  - based on latest asymptotic findings 
  - Bayesian, but straightforward 
  - Assume: Up to $K$ groups  are normally distributed with an unknown mean and variance. 

## Algorithm
- modelling requires no additional assumptions beyond defaults
- extra covariates can be explored later 
    - could also use mixtures of regressions too... 
    - > assumptions and decisions to make later on

## Code outline

Install the package
```{r, eval=FALSE}
install_github('zoevanhavre/Zmix') # Thank you Hadley!
library(Zmix)
```

Run the model with 5 groups

```{r, eval=FALSE}
Zmix.Y<-Zmix_univ_tempered(Y, iter=50000, k=5) 
```

Process the results
```{r, eval=FALSE}
Proc.Zmix.Y<-Process_Output_Zmix(Zmix.Y, Burn=25000)
```


[Check out the README for more examples](https://github.com/zoevanhavre/Zmix)


# Results


--------------

```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
require(ggplot2, quietly=TRUE)
	gp.PropHigh.1<-ggplot(SUVR_ProportionHigh.1, aes(x=Region, y=PropHigh))+ geom_bar(stat="identity", fill="cyan2") + ggtitle("Prevalence of second cluster")+ xlab("Regions")+theme_bw()+ylab("Proportion of (HC) Patients")+theme(axis.text.x = element_text(angle = 90, hjust = 1))
	# PLOT!!!
	gp.PropHigh.1
```


--------------

```{r, echo=FALSE, warning=FALSE, fig.width = 4 , fig.height = 3, cache=TRUE}
require(ggplot2, quietly=TRUE)
DensityPlot_HC(5)
DensityPlot_HC(10)
DensityPlot_HC(15)
DensityPlot_HC(29)

```

-----------

```{r, echo=FALSE, warning=FALSE,, fig.width = 4 , fig.height = 3,cache=TRUE}
require(ggplot2, quietly=TRUE)

DensityPlot_Both(5)
DensityPlot_Both(10)
DensityPlot_Both(15)
DensityPlot_Both(29)

```



----------
```{r, echo=FALSE, warning=FALSE,, fig.width = 4 , fig.height = 3,cache=TRUE}
require(ggplot2, quietly=TRUE)

	ggplot(cr.tm.K02, aes( Region , Mu))+
		geom_boxplot(aes(col=factor(k)), outlier.size=0.1)+ggtitle("HC, ordered by lower means")+
		theme(axis.text.x = element_text(angle = 90, hjust = 1))+geom_hline(yintercept=1.5 )



```

-----------

```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
require(tidyr, quietly=TRUE)
heatmap.3(t(ForSIMI_num),col=c( "dodgerblue4", "cyan2"),hclust=hclustfunc, distfun=distfunc,   key=FALSE, margins = c(2,8),cexRow = .6,cexCol = 0.001, xlab="Patients (HC only)")

```

## Results overview

- Zmix found either **one** or **two** groups 
- Majority of regions result in two clusters, 
- Prevalence of 2nd group similar across regions, 
- Allocations to 2nd group highly correlated (across individuals)
- The HC clusters with larger means resemble the distribution of SUVR in AD, shifted to a lower mean, (as would be expected in early stages of the disease).
- They also follow a similar pattern across regions to AD 

-------

```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
require(tidyr, quietly=TRUE)
require(ggplot2, quietly=TRUE)

df.new<-aggregate(ApoE~ Region+k_hilo, droplevels(top_demogs),function(x) prop.table(table(x)) )
df.new<-as.data.frame(as.matrix(df.new))
df.new.t<-gather(df.new,key=Genotype, value=Proportion,ApoE.ApoE_Neg,  ApoE.ApoE_Pos  )
df.new.t$Proportion<- factor2numeric( df.new.t$Proportion)
levels(df.new.t$k_hilo)<-c("HC: high mean group","HC: low mean group")
ggplot(df.new.t,aes(Region,Proportion))+geom_bar(aes(fill=Genotype),stat="identity",position='dodge')+facet_grid(~k_hilo)+theme_bw() +  theme(axis.text.x = element_text(angle = 90, hjust = 1), axis.text.y = element_text( hjust = 1))+ggtitle("Genotype by Zmix cluster")+ scale_fill_manual("Genotype",labels=c("ApoE- (good)", "ApoE+ (bad)"), values=c("red", "yellow"))  


```

-------------


```{r, echo=FALSE,warning=FALSE, fig.height = 6, fig.width = 8, message=FALSE}
require(tidyr, quietly=TRUE)

# memory status
df.new<-aggregate(Austin~ Region+k_hilo, droplevels(top_demogs),function(x) prop.table(table(x)) )
df.new<-as.data.frame(as.matrix(df.new))
df.new.t<-gather(df.new,key=Diagnosis, value=Proportion,3,   4  )
df.new.t$Proportion<- factor2numeric( df.new.t$Proportion)
levels(df.new.t$Diagnosis)<-c("Memory Complainer (HC)"   ,  "Non-Memory Complainer (HC)")
levels(df.new.t$k_hilo)<-c("HC: high mean group","HC: low mean group")
ggplot(df.new.t,aes(Region,Proportion))+geom_bar(aes(fill=Diagnosis),stat="identity",position='dodge')+facet_grid(~k_hilo)+theme_bw() +  theme(axis.text.x = element_text(angle = 90, hjust = 1), axis.text.y = element_text( hjust = 1))+ggtitle("Memory Status by Zmix cluster")+ scale_fill_manual("Memory",labels=c("Complainer", "Non-Complainer"), values=c("orange", "green"))  
  
```




## Slide with image
<img src="Images/hc_diff_means.png" style="width: 800px"/>


